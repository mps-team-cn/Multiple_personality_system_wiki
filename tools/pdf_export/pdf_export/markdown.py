"""ç»„åˆ Markdown å†…å®¹ã€ç”Ÿæˆç›®å½•ä¸å°é¢ç­‰è¾…åŠ©å‡½æ•°é›†åˆã€‚"""

from __future__ import annotations

import hashlib
import re
from collections.abc import Mapping
from pathlib import Path

from .paths import PROJECT_ROOT, README_PATH

# Markdown ä¸­æŒ‡å‘è¯æ¡çš„å¸¸è§é“¾æ¥æ ¼å¼ï¼š
# - è¡Œå†…é“¾æ¥ [æè¿°](entries/è¯æ¡.md) æˆ– [æè¿°](è¯æ¡.md)
# - å¼•ç”¨å¼é“¾æ¥ [ref]: entries/è¯æ¡.md æˆ– [ref]: è¯æ¡.md
# - è§’æ‹¬å·è‡ªåŠ¨é“¾æ¥ <entries/è¯æ¡.md> æˆ– <è¯æ¡.md>
#
# PDF å¯¼å‡ºæ—¶ä¼šå°†æ‰€æœ‰è¯æ¡åˆå¹¶ä¸ºå•ä¸€æ–‡æ¡£ï¼Œå› æ­¤éœ€è¦å°†è¿™äº›é“¾æ¥
# ç»Ÿä¸€é‡å†™ä¸ºæŒ‡å‘åˆå¹¶æ–‡æ¡£å†…éƒ¨é”šç‚¹çš„å½¢å¼ã€‚æ­£åˆ™è¡¨è¾¾å¼ä»…æ•è·é“¾æ¥
# çš„å‰ç¼€/ç›®æ ‡/åç¼€éƒ¨åˆ†ï¼Œä¾¿äºåœ¨æ›¿æ¢æ—¶ä¿ç•™åŸæœ‰æ’ç‰ˆç»†èŠ‚ã€‚
#
# æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
# 1. æ—§æ ¼å¼ï¼šentries/xxx.md æˆ– ./entries/xxx.md æˆ– ../entries/xxx.md
# 2. æ–°æ ¼å¼ï¼šxxx.mdï¼ˆç›¸å¯¹è·¯å¾„ï¼Œå‡å®šåœ¨ docs/entries/ ç›®å½•ä¸‹ï¼‰
ENTRY_INLINE_LINK_PATTERN = re.compile(
    r"(?P<prefix>\[[^\]]+\]\()(?P<target>(?:(?:\./|\.\./|)entries/)?[^)#\s/]+?\.md)"
    r"(?P<fragment>#[^)\s]*)?(?P<suffix>\))"
)

ENTRY_REFERENCE_LINK_PATTERN = re.compile(
    r"(?P<prefix>^\s*\[[^\]]+\]:\s*)(?P<target>(?:(?:\./|\.\./|)entries/)?[^#\s/]+?\.md)"
    r"(?P<fragment>#[^\s]*)?(?P<suffix>\s*$)",
    re.MULTILINE,
)

ENTRY_ANGLE_LINK_PATTERN = re.compile(
    r"(?P<prefix><)(?P<target>(?:(?:\./|\.\./|)entries/)?[^>#\s/]+?\.md)"
    r"(?P<fragment>#[^>\s]*)?(?P<suffix>>)",
)

from .last_updated import LastUpdatedInfo, render_last_updated_text
from .models import CategoryStructure, EntryDocument

# MkDocs Material Admonitions åŒ¹é…æ¨¡å¼
# æ ¼å¼: !!! type "title" æˆ– ??? type "title" æˆ– ???+ type "title"
#           content (ç¼©è¿›4ç©ºæ ¼)
# æ”¯æŒï¼š
#   - !!! = ä¸å¯æŠ˜å çš„ admonition
#   - ??? = é»˜è®¤æŠ˜å çš„ admonition
#   - ???+ = é»˜è®¤å±•å¼€çš„å¯æŠ˜å  admonition
ADMONITION_PATTERN = re.compile(
    r'^(?P<marker>!!!|\?\?\?\+?) +(?P<type>\w+)(?: +"(?P<title>[^"]+)")?\s*$',
    re.MULTILINE
)

# Admonitions ç±»å‹åˆ° LaTeX æ ·å¼çš„æ˜ å°„
ADMONITION_STYLES = {
    "note": ("å¤‡æ³¨", "gray"),
    "abstract": ("æ‘˜è¦", "gray"),
    "info": ("ä¿¡æ¯", "blue"),
    "tip": ("æç¤º", "green"),
    "success": ("æˆåŠŸ", "green"),
    "question": ("é—®é¢˜", "yellow"),
    "warning": ("è­¦å‘Š", "orange"),
    "failure": ("å¤±è´¥", "red"),
    "danger": ("å±é™©", "red"),
    "bug": ("é”™è¯¯", "red"),
    "example": ("ç¤ºä¾‹", "purple"),
    "quote": ("å¼•ç”¨", "gray"),
}


LATEX_SPECIAL_CHARS = {
    "\\": r"\textbackslash{}",
    "{": r"\{",
    "}": r"\}",
    "$": r"\$",
    "&": r"\&",
    "#": r"\#",
    "_": r"\_",
    "%": r"\%",
    "~": r"\textasciitilde{}",
    "^": r"\textasciicircum{}",
}


def escape_latex(text: str) -> str:
    """å¯¹ ``text`` ä¸­çš„ LaTeX ç‰¹æ®Šå­—ç¬¦åšè½¬ä¹‰ã€‚"""

    return "".join(LATEX_SPECIAL_CHARS.get(ch, ch) for ch in text)


def infer_entry_title(path: Path) -> str:
    """å°½åŠ›ä»æ¡ç›®æ–‡ä»¶æ¨æ–­å±•ç¤ºæ ‡é¢˜ï¼Œå¤±è´¥æ—¶å›é€€åˆ°æ–‡ä»¶åã€‚"""

    heading_pattern = re.compile(r"^#{1,6}\s+(?P<title>.+?)\s*$")
    try:
        for raw_line in path.read_text(encoding="utf-8").splitlines():
            match = heading_pattern.match(raw_line.strip())
            if match:
                return match.group("title").strip()
    except OSError:
        pass

    return path.stem


def shift_heading_levels(markdown: str, offset: int) -> str:
    """å°†æ‰€æœ‰æ ‡é¢˜çº§åˆ«æ•´ä½“ä¸Šç§» ``offset``ï¼ŒåŒæ—¶ä¿ç•™ Pandoc ä»£ç å—ã€‚"""

    if offset == 0:
        return markdown

    pattern = re.compile(r"^(#{1,6})(\s+)(.*)$", re.MULTILINE)

    def _replace(match: re.Match[str]) -> str:
        hashes, spacing, title = match.groups()
        new_level = min(6, len(hashes) + offset)
        return f"{'#' * new_level}{spacing}{title}"

    return pattern.sub(_replace, markdown)


def build_entry_anchor(path: Path) -> str:
    """åŸºäºè·¯å¾„ç”Ÿæˆç¨³å®šé”šç‚¹ï¼Œç¡®ä¿åˆå¹¶æ–‡æ¡£ä¸­çš„å¼•ç”¨å¯é‡å¤ã€‚"""

    relative = path.relative_to(PROJECT_ROOT)
    digest = hashlib.sha1(relative.as_posix().encode("utf-8")).hexdigest()[:10]
    return f"entry-{digest}"


def _build_anchor_lookup(structure: CategoryStructure) -> dict[Path, str]:
    """ä¸ºæ‰€æœ‰å¯¼å‡ºæ¡ç›®ç”Ÿæˆâ€œç»å¯¹è·¯å¾„ â†’ é”šç‚¹â€æ˜ å°„ã€‚"""

    lookup: dict[Path, str] = {}
    for _, documents in structure:
        for document in documents:
            lookup[document.path.resolve()] = build_entry_anchor(document.path)
    return lookup


def _resolve_entry_target(target: str, lookup: Mapping[Path, str]) -> str | None:
    """æ ¹æ® ``target`` æŸ¥æ‰¾å¯¹åº”çš„åˆå¹¶æ–‡æ¡£é”šç‚¹ã€‚

    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. åŒ…å« entries/ çš„è·¯å¾„ï¼šentries/xxx.md, ./entries/xxx.md, ../entries/xxx.md
    2. ç›¸å¯¹è·¯å¾„ï¼šxxx.mdï¼ˆå‡å®šåœ¨ docs/entries/ ç›®å½•ä¸‹ï¼‰
    """

    stripped = target.strip()
    if not stripped:
        return None

    candidates: list[Path] = []

    # æ£€æŸ¥æ˜¯å¦åŒ…å« "entries/"
    index = stripped.find("entries/")
    if index != -1:
        # æ—§æ ¼å¼ï¼šentries/xxx.md æˆ–å…¶ç›¸å¯¹å†™æ³•
        relative_target = Path(stripped[index:])
        candidates.append(relative_target)
        # å…¼å®¹ MkDocs æ–°ç›®å½•ç»“æ„ä¸‹çš„ docs/entries/ ä½ç½®
        if relative_target.parts and relative_target.parts[0] != "docs":
            candidates.append(Path("docs") / relative_target)
    else:
        # æ–°æ ¼å¼ï¼šçº¯æ–‡ä»¶åï¼Œå‡å®šä½äº docs/entries/ ä¸‹
        if not stripped.endswith(".md"):
            return None
        # é¿å…åŒ¹é…è·¯å¾„ä¸­åŒ…å« / çš„æƒ…å†µï¼ˆä¾‹å¦‚ foo/bar.mdï¼‰
        if "/" in stripped or "\\" in stripped:
            return None
        candidates.append(Path("docs/entries") / stripped)
        # ä¸ºå‘åå…¼å®¹ä¿ç•™ entries/xxx.md å½¢å¼
        candidates.append(Path("entries") / stripped)

    for candidate in candidates:
        if candidate.is_absolute():
            continue
        try:
            resolved = (PROJECT_ROOT / candidate).resolve()
        except OSError:
            continue

        anchor = lookup.get(resolved)
        if anchor:
            return f"#{anchor}"

    return None


def rewrite_entry_links(markdown: str, lookup: Mapping[Path, str]) -> str:
    """å°† Markdown ä¸­çš„è¯æ¡é“¾æ¥é‡å†™ä¸º PDF å†…éƒ¨é”šç‚¹ã€‚"""

    def _replace(match: re.Match[str]) -> str:
        target = match.group("target")
        resolved = _resolve_entry_target(target, lookup)
        if not resolved:
            return match.group(0)
        # PDF åˆå¹¶åä»…èƒ½è·³è½¬åˆ°è¯æ¡èµ·å§‹ä½ç½®ï¼Œå¿½ç•¥åŸæœ‰å±€éƒ¨é”šç‚¹ã€‚
        return f"{match.group('prefix')}{resolved}{match.group('suffix')}"

    updated = ENTRY_INLINE_LINK_PATTERN.sub(_replace, markdown)
    updated = ENTRY_REFERENCE_LINK_PATTERN.sub(_replace, updated)
    updated = ENTRY_ANGLE_LINK_PATTERN.sub(_replace, updated)
    return updated


def strip_primary_heading(content: str, title: str) -> str:
    """ç§»é™¤ä¸ ``title`` ç›¸åŒçš„é¦–ä¸ªæ ‡é¢˜ï¼Œé¿å…é‡å¤æ ‡é¢˜å¹²æ‰°ã€‚"""

    heading_re = re.compile(rf"^#{{1,6}}\s+{re.escape(title)}\s*$")
    lines = content.splitlines()
    stripped: list[str] = []
    removed = False

    index = 0
    while index < len(lines):
        current = lines[index]
        if not removed and heading_re.match(current.strip()):
            removed = True
            index += 1
            if index < len(lines) and not lines[index].strip():
                index += 1
            continue
        stripped.append(current)
        index += 1

    return "\n".join(stripped)


def convert_html_br_tags(markdown: str) -> str:
    """å°† HTML æ¢è¡Œæ ‡ç­¾ <br>, <br/>, <br /> è½¬æ¢ä¸º Markdown åŒç©ºæ ¼æ¢è¡Œæˆ– LaTeX \\\\ã€‚

    åœ¨è¡¨æ ¼ä¸­ä½¿ç”¨åŒåæ–œæ  \\\\ï¼Œåœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨åŒç©ºæ ¼ + æ¢è¡Œï¼Œå¹¶ä¿ç•™åŸå§‹è¡Œçš„ç¼©è¿›ã€‚
    è¿™ç¡®ä¿äº†ç¼©è¿›å—ï¼ˆå¦‚ admonitionsã€åˆ—è¡¨é¡¹ï¼‰ä¸­çš„ <br> æ ‡ç­¾è½¬æ¢åä¸ä¼šç ´åå—ç»“æ„ã€‚
    """
    # åŒ¹é… <br>ã€<br/>ã€<br /> ç­‰å„ç§å½¢å¼
    br_pattern = re.compile(r'<br\s*/?\s*>', re.IGNORECASE)

    # åœ¨è¡¨æ ¼è¡Œä¸­ï¼ˆä»¥ | å¼€å§‹çš„è¡Œï¼‰ï¼Œå°† <br> æ›¿æ¢ä¸º \\
    lines = markdown.splitlines()
    result = []

    for line in lines:
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼è¡Œï¼ˆåŒ…å« | å­—ç¬¦ï¼‰
        if '|' in line and not line.strip().startswith('#'):
            # åœ¨è¡¨æ ¼ä¸­ä½¿ç”¨åŒåæ–œæ 
            result.append(br_pattern.sub(r'\\\\', line))
        else:
            # åœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨åŒç©ºæ ¼ + æ¢è¡Œï¼Œå¹¶ä¿ç•™åŸå§‹ç¼©è¿›
            # æå–è¡Œé¦–ç¼©è¿›
            leading_spaces = len(line) - len(line.lstrip())
            indent = line[:leading_spaces]

            # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—è¡¨é¡¹ï¼ˆ- , * , æˆ–æ•°å­—.ï¼‰
            stripped = line.lstrip()
            list_match = re.match(r'^([*\-+]|\d+\.)\s+', stripped)
            if list_match:
                # åˆ—è¡¨é¡¹ï¼šç»­è¡Œéœ€è¦é¢å¤–ç¼©è¿›ä»¥å¯¹é½åˆ—è¡¨å†…å®¹
                # è®¡ç®—åˆ—è¡¨æ ‡è®°çš„é•¿åº¦ï¼ˆä¾‹å¦‚ "- " æ˜¯ 2ï¼Œ"1. " æ˜¯ 3ï¼‰
                list_marker_len = len(list_match.group(0))
                # ç»­è¡Œç¼©è¿› = åŸå§‹ç¼©è¿› + åˆ—è¡¨æ ‡è®°é•¿åº¦
                continuation_indent = indent + ' ' * list_marker_len
                converted = br_pattern.sub(f'  \n{continuation_indent}', line)
            else:
                # æ™®é€šè¡Œæˆ–å·²ç¼©è¿›çš„å—ï¼šä½¿ç”¨ç›¸åŒç¼©è¿›
                converted = br_pattern.sub(f'  \n{indent}', line)

            result.append(converted)

    return '\n'.join(result)


def convert_admonitions_to_latex(markdown: str) -> str:
    """å°† MkDocs Material admonitions è½¬æ¢ä¸º LaTeX æ ¼å¼çš„æ¡†ã€‚

    MkDocs æ ¼å¼:
        !!! warning "æ ‡é¢˜"
            å†…å®¹è¡Œ1
            å†…å®¹è¡Œ2

    è½¬æ¢ä¸º Pandoc/LaTeX å…¼å®¹çš„å—å¼•ç”¨æ ¼å¼:
        > **âš ï¸ è­¦å‘Š: æ ‡é¢˜**
        >
        > å†…å®¹è¡Œ1
        > å†…å®¹è¡Œ2

    æ”¯æŒåµŒå¥—åœ¨åˆ—è¡¨ä¸­çš„ admonitionï¼ˆå¸¦æœ‰é¢å¤–ç¼©è¿›ï¼‰ã€‚
    """
    lines = markdown.splitlines()
    result = []
    i = 0

    while i < len(lines):
        line = lines[i]
        match = ADMONITION_PATTERN.match(line)

        if match:
            admon_type = match.group("type").lower()
            title = match.group("title") or ""

            # æ£€æµ‹ admonition è¡Œçš„å‰å¯¼ç©ºæ ¼ï¼ˆç”¨äºå¤„ç†åµŒå¥—ï¼‰
            leading_spaces = len(line) - len(line.lstrip())

            # è·å–ç±»å‹å¯¹åº”çš„ä¸­æ–‡åç§°å’Œå›¾æ ‡
            type_name, _ = ADMONITION_STYLES.get(admon_type, (admon_type.capitalize(), "gray"))

            # å›¾æ ‡æ˜ å°„
            icon_map = {
                "warning": "âš ï¸",
                "danger": "ğŸš«",
                "info": "â„¹ï¸",
                "tip": "ğŸ’¡",
                "note": "ğŸ“",
                "success": "âœ…",
                "failure": "âŒ",
                "bug": "ğŸ›",
                "example": "ğŸ“‹",
                "question": "â“",
                "quote": "ğŸ’¬",
                "abstract": "ğŸ“„",
            }
            icon = icon_map.get(admon_type, "ğŸ“Œ")

            # æ„å»ºæ ‡é¢˜è¡Œï¼ˆä¿ç•™åŸæœ‰ç¼©è¿›ï¼‰
            indent = " " * leading_spaces
            if title:
                header = f"{indent}> **{icon} {type_name}: {title}**"
            else:
                header = f"{indent}> **{icon} {type_name}**"

            result.append(header)
            result.append(f"{indent}>")

            # æ”¶é›†ç¼©è¿›å†…å®¹ï¼ˆè‡³å°‘éœ€è¦ leading_spaces + 4 ä¸ªç©ºæ ¼ï¼‰
            min_indent = leading_spaces + 4
            i += 1
            while i < len(lines):
                content_line = lines[i]

                # æ£€æŸ¥æ˜¯å¦æ˜¯ admonition å†…å®¹ï¼ˆç¼©è¿›è¡Œï¼‰æˆ–ç©ºè¡Œ
                if len(content_line) >= min_indent and content_line[:min_indent] == " " * min_indent:
                    # ç§»é™¤åŸºç¡€ç¼©è¿›ï¼ˆleading_spaces + 4ï¼‰ï¼Œä¿ç•™é¢å¤–ç¼©è¿›ï¼Œæ·»åŠ å¼•ç”¨æ ‡è®°
                    result.append(f"{indent}> {content_line[min_indent:]}")
                    i += 1
                elif not content_line.strip():
                    # ç©ºè¡Œï¼Œå¯èƒ½æ˜¯ admonition å†…éƒ¨çš„æ®µè½åˆ†éš”
                    # å…ˆæ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦è¿˜æ˜¯ç¼©è¿›å†…å®¹
                    if i + 1 < len(lines) and len(lines[i + 1]) >= min_indent and lines[i + 1][:min_indent] == " " * min_indent:
                        result.append(f"{indent}>")
                        i += 1
                    else:
                        # admonition ç»“æŸ
                        break
                else:
                    # éç¼©è¿›è¡Œï¼Œadmonition ç»“æŸ
                    break

            # æ·»åŠ ç©ºè¡Œåˆ†éš”
            result.append("")
        else:
            result.append(line)
            i += 1

    return "\n".join(result)


def build_cover_page(
    title: str,
    subtitle: str | None,
    date_text: str | None,
    footer_text: str | None,
    online_link_label: str | None,
    online_link_url: str | None,
) -> str:
    """ä½¿ç”¨ LaTeX ``titlepage`` ç¯å¢ƒæ„å»ºå°é¢é¡µã€‚"""

    def _format_line(size_command: str, text: str, *, italic: bool = False) -> str:
        """ä»¥æŒ‡å®šå­—å·æŒ‡ä»¤æ¸²æŸ“ ``text``ï¼ŒåŒæ—¶å®Œæˆè½¬ä¹‰ã€‚"""

        escaped = escape_latex(text.strip())
        content = f"\\textit{{{escaped}}}" if italic else escaped
        return f"{{{size_command} {content}\\par}}"

    def _format_link_line(size_command: str, label: str, url: str) -> str:
        """æ„å»ºå¸¦è¶…é“¾æ¥çš„å­—å·è¡Œã€‚"""

        label_escaped = escape_latex(label.strip())
        url_escaped = escape_latex(url.strip())
        return f"{{{size_command} \\href{{{url_escaped}}}{{{label_escaped}}}\\par}}"

    lines = [
        "\\begin{titlepage}",
        "\\centering",
        "\\vspace*{3cm}",
        _format_line("\\Huge", title),
    ]

    if subtitle:
        lines.extend([
            "\\vspace{1.5cm}",
            _format_line("\\Large", subtitle),
        ])

    if online_link_label and online_link_url:
        lines.extend([
            "\\vspace{1.2cm}",
            _format_link_line("\\Large", online_link_label, online_link_url),
        ])

    bottom_inserted = False

    if date_text:
        lines.extend([
            "\\vfill",
            _format_line("\\large", date_text),
        ])
        bottom_inserted = True

    if footer_text:
        if bottom_inserted:
            lines.append("\\vspace{0.8cm}")
        else:
            lines.append("\\vfill")
        lines.append(_format_line("\\Large", footer_text, italic=True))

    lines.extend([
        "\\vspace{1cm}",
        "\\end{titlepage}",
        "",
        "\\newpage",
        "",
    ])

    return "\n".join(lines)


def build_directory_page(
    structure: CategoryStructure, anchor_lookup: Mapping[Path, str]
) -> str:
    """æ ¹æ® ``structure`` ç”Ÿæˆå¸¦é¡µç çš„ç›®å½•é¡µã€‚"""

    lines: list[str] = ["# ç›®å½•", ""]
    lines.extend(
        [
            r"\begingroup",
            r"\setlength{\parindent}{0pt}",
            r"\setlength{\parskip}{0.4em}",
            "",
        ]
    )

    for category_title, documents in structure:
        if not documents:
            continue

        lines.append(rf"\textbf{{{escape_latex(category_title)}}}\par")
        lines.append(r"\vspace{0.2em}")

        for document in documents:
            anchor = anchor_lookup.get(
                document.path.resolve(),
                build_entry_anchor(document.path),
            )
            entry_title = escape_latex(document.title)
            lines.append(
                rf"\noindent\hspace{{1em}}\textbullet\hspace{{0.6em}}"
                rf"\hyperref[{anchor}]{{{entry_title}}}"
                rf"\nobreak\dotfill\pageref{{{anchor}}}\par"
            )

        lines.append(r"\medskip")

    lines.extend([r"\endgroup", "", r"\newpage", ""])
    return "\n".join(lines)


def build_combined_markdown(
    preface_doc: EntryDocument | None,
    structure: CategoryStructure,
    include_readme: bool,
    include_cover: bool,
    cover_title: str,
    cover_subtitle: str | None,
    cover_date: str | None,
    cover_footer: str | None,
    cover_online_link_label: str | None,
    cover_online_link_url: str | None,
    last_updated_map: Mapping[str, LastUpdatedInfo] | None = None,
) -> str:
    """å°†æ‰€æœ‰ Markdown æ–‡ä»¶æ‹¼æ¥ä¸ºå•ä¸€å­—ç¬¦ä¸²ä¾› Pandoc ä½¿ç”¨ã€‚

    é¡ºåº: å°é¢ -> ç›®å½• -> å‰è¨€ -> README -> å†…å®¹ç« èŠ‚
    """

    parts: list[str] = []
    anchor_lookup = _build_anchor_lookup(structure)

    # 1. å°é¢é¡µ (LaTeX titlepage)
    if include_cover:
        parts.append(
            build_cover_page(
                title=cover_title,
                subtitle=cover_subtitle,
                date_text=cover_date,
                footer_text=cover_footer,
                online_link_label=cover_online_link_label,
                online_link_url=cover_online_link_url,
            )
        )

    # 2. ç›®å½•é¡µ
    if structure:
        parts.append(build_directory_page(structure, anchor_lookup))

    # 3. å‰è¨€ï¼ˆç‹¬ç«‹ç« èŠ‚ï¼Œä¸åœ¨ç›®å½•ä¸­åˆ—å‡ºï¼‰
    if preface_doc:
        # ä¸ºå‰è¨€ç”Ÿæˆé”šç‚¹
        preface_anchor = build_entry_anchor(preface_doc.path)
        relative = preface_doc.path.relative_to(PROJECT_ROOT)
        rewritten = rewrite_entry_links(preface_doc.body, anchor_lookup)
        # è½¬æ¢ HTML æ¢è¡Œæ ‡ç­¾
        br_converted = convert_html_br_tags(rewritten)
        # è½¬æ¢ admonitions
        converted = convert_admonitions_to_latex(br_converted)
        body = strip_primary_heading(converted, preface_doc.title)
        shifted = shift_heading_levels(body, offset=1).strip()

        parts.append(f"# {preface_doc.title} {{#{preface_anchor}}}\n\n")
        if last_updated_map:
            repo_path = relative.as_posix()
            last_updated_text = render_last_updated_text(repo_path, last_updated_map)
            if last_updated_text:
                parts.append(f"{last_updated_text}\n\n")
        if shifted:
            parts.append(shifted)
            parts.append("\n\n")
        parts.append(f"<!-- æ¥æº: {relative.as_posix()} -->\n\n")
        parts.append("\\newpage\n\n")

    # 4. README
    if include_readme and README_PATH.exists():
        readme_content = README_PATH.read_text(encoding="utf-8").strip()
        # è½¬æ¢ HTML æ¢è¡Œæ ‡ç­¾
        readme_br_converted = convert_html_br_tags(readme_content)
        # è½¬æ¢ admonitions
        readme_converted = convert_admonitions_to_latex(readme_br_converted)
        parts.append(readme_converted)
        parts.append("\n\n\\newpage\n")

    # 5. å†…å®¹ç« èŠ‚
    first_category = True
    for category_title, documents in structure:
        if not documents:
            continue

        if not first_category:
            parts.append("\n\\newpage\n")
        first_category = False

        parts.append(f"# {category_title}\n\n")

        for index, document in enumerate(documents):
            if index > 0:
                parts.append("\n\\newpage\n")

            entry_title = document.title
            anchor = anchor_lookup.get(
                document.path.resolve(),
                build_entry_anchor(document.path),
            )
            relative = document.path.relative_to(PROJECT_ROOT)
            rewritten = rewrite_entry_links(document.body, anchor_lookup)
            # è½¬æ¢ HTML æ¢è¡Œæ ‡ç­¾
            br_converted = convert_html_br_tags(rewritten)
            # è½¬æ¢ admonitions
            converted = convert_admonitions_to_latex(br_converted)
            body = strip_primary_heading(converted, entry_title)
            shifted = shift_heading_levels(body, offset=2).strip()

            parts.append(f"## {entry_title} {{#{anchor}}}\n\n")
            if last_updated_map:
                repo_path = relative.as_posix()
                last_updated_text = render_last_updated_text(repo_path, last_updated_map)
                if last_updated_text:
                    parts.append(f"{last_updated_text}\n\n")
            if shifted:
                parts.append(shifted)
                parts.append("\n\n")
            parts.append(f"<!-- æ¥æº: {relative.as_posix()} -->\n\n")

    combined = "".join(parts).strip()
    if not combined.endswith("\n"):
        combined += "\n"
    return combined
